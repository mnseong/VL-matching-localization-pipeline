{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c7217d-8e6d-4803-8d6c-4c213d53e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e0d6d0f-5b07-453f-b583-63ebd26c8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_for_name(module_name, class_name):\n",
    "    # load the module, will raise ImportError if module cannot be loaded\n",
    "    m = importlib.import_module(module_name)\n",
    "    return getattr(m, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d7dcdc5-eb3b-4ec4-b581-ebc05f6b8b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv(nn.Module):\n",
    "    def __init__(self, num_in_layers, num_out_layers, kernel_size, stride):\n",
    "        super(conv, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(num_in_layers,\n",
    "                              num_out_layers,\n",
    "                              kernel_size=kernel_size,\n",
    "                              stride=stride,\n",
    "                              padding=(self.kernel_size - 1) // 2)\n",
    "        self.gn = nn.GroupNorm(num_groups=32,num_channels=num_out_layers) # Group Norm with 32\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.elu(self.gn(self.conv(x)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f2b8e6-5db5-4874-afdc-80b385c747b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class upconv(nn.Module):\n",
    "    def __init__(self, num_in_layers, num_out_layers, kernel_size, scale):\n",
    "        super(upconv, self).__init__()\n",
    "        self.scale  = scale\n",
    "        self.conv   = conv(num_in_layers, num_out_layers, kernel_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.interpolate(x, scale_factor=self.scale, align_corners=True, mode='bilinear')\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2133a9d-1bd2-4672-ae3a-02c652bbab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class upconv_like(nn.Module):\n",
    "    def __init__(self, num_in_layers, num_out_layers, kernel_size):\n",
    "        super(upconv_like, self).__init__()\n",
    "\n",
    "        self.conv = conv(num_in_layers, num_out_layers, kernel_size, 1)\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        x = F.upsample(x,size=target.shape[2:],mode='bilinear')\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d78e6c-705e-4abb-8eab-db1ccab82ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squeeze_Excite_Block(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(Squeeze_Excite_Block, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131f21ca-2824-4cbc-8375-7f7ba3f51c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseNorm2(nn.Module):\n",
    "    def __init__(self, epsilon=1e-5):\n",
    "        super().__init__()\n",
    "        self.epsilon    = epsilon\n",
    "        self.conv1      = nn.Conv2d(1,1,kernel_size=7,stride=1,padding=3)\n",
    "        self.conv2      = nn.Conv2d(1, 1, kernel_size=7, stride=1, padding=3)\n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim=1, keepdim=True)\n",
    "        std = x.var(dim=1, keepdim=True).add(self.epsilon).sqrt()\n",
    "        output = (x - mean) / std\n",
    "        map = torch.mean(x,dim=1, keepdim=True)\n",
    "        map1 = self.conv1(map)\n",
    "        map2 = self.conv2(map)\n",
    "        return output*map1 + map2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f45c1822-4387-4cff-a554-9ef0f1906a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaffusion(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super().__init__()\n",
    "        self.num_channels   = num_channels\n",
    "        self.avg_pool       = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1            = nn.Linear(128,64)\n",
    "        self.relu1          = nn.ReLU()\n",
    "        self.fc2            = nn.Linear(64,128)\n",
    "        self.fc3            = nn.Linear(128, 64)\n",
    "        self.relu2          = nn.ReLU()\n",
    "        self.fc4            = nn.Linear(64, 128)\n",
    "\n",
    "    def forward(self, result, x):\n",
    "        avg_out1 = self.fc2(self.relu1(self.fc1(self.avg_pool(x).squeeze(-1).squeeze(-1)))).unsqueeze(-1).unsqueeze(-1)\n",
    "        avg_out2 = self.fc4(self.relu2(self.fc3(self.avg_pool(x).squeeze(-1).squeeze(-1)))).unsqueeze(-1).unsqueeze(-1)\n",
    "        return result * avg_out1 + avg_out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6958528-5f8e-43e3-b449-23b01d1c5af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelwiseNorm(nn.Module):\n",
    "    def __init__(self, num_features, momentum=0.9, eps=1e-5, affusion=False, track_running_stats=False):\n",
    "        super().__init__()\n",
    "        self.momentum = momentum\n",
    "        self.eps = eps\n",
    "\n",
    "        if affusion:\n",
    "            self.affusion = Adaffusion(num_features)\n",
    "        else:\n",
    "            self.affusion = None\n",
    "\n",
    "        self.track_running_stats = track_running_stats\n",
    "        if track_running_stats:\n",
    "            self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "            self.register_buffer('running_var', torch.ones(num_features))\n",
    "        else:\n",
    "            self.register_parameter('running_mean', None)\n",
    "            self.register_parameter('running_var', None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 4\n",
    "        b, c, h, w = x.shape\n",
    "\n",
    "        if self.training or not self.track_running_stats:\n",
    "            # All dims except for B and C\n",
    "            mu = x.mean(dim=(2, 3))\n",
    "            sigma = x.var(dim=(2, 3), unbiased=False)\n",
    "        else:\n",
    "            mu, sigma = self.running_mean, self.running_var\n",
    "            b = 1\n",
    "\n",
    "        if self.training and self.track_running_stats:\n",
    "            sigma_unbiased = sigma * ((h * w) / ((h * w) - 1))\n",
    "            self.running_mean   = self.running_mean * (1 - self.momentum) + mu.mean(dim=0) * self.momentum\n",
    "            self.running_var    = self.running_var * (1 - self.momentum) + sigma_unbiased.mean(dim=0) * self.momentum\n",
    "\n",
    "        mu = mu.reshape(b, c, 1, 1)\n",
    "        sigma = sigma.reshape(b, c, 1, 1)\n",
    "        result = (x - mu) / torch.sqrt(sigma + self.eps)\n",
    "\n",
    "        if self.affusion is not None:\n",
    "            result = self.affusion(result)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "871b303f-01c5-43cc-8eca-2179b9b5d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResUNet_F2R(nn.Module):\n",
    "    \"\"\"\n",
    "    F2R-Backbone: Feature-Fusion-ResUNet Backbone\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 encoder='resnet50',\n",
    "                 pretrained=True,\n",
    "                 fusion_out_ch=128\n",
    "                 ):\n",
    "\n",
    "        super(ResUNet_F2R, self).__init__()\n",
    "        assert encoder in ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152'], \"Incorrect encoder type\"\n",
    "        if encoder in ['resnet18', 'resnet34']:\n",
    "            filters = [64, 128, 256, 512]\n",
    "        else:\n",
    "            filters = [256, 512, 1024, 2048]\n",
    "        resnet = class_for_name(\"torchvision.models\", encoder)(pretrained=pretrained)\n",
    "\n",
    "        self.firstconv      = resnet.conv1  # H/2\n",
    "        self.firstbn        = resnet.bn1\n",
    "        self.firstrelu      = resnet.relu\n",
    "        self.firstmaxpool   = resnet.maxpool  # H/4\n",
    "\n",
    "        # Encoder\n",
    "        self.layer1 = resnet.layer1  # H/4\n",
    "        self.layer2 = resnet.layer2  # H/8\n",
    "        self.layer3 = resnet.layer3  # H/16\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv3    = upconv(filters[2], 512, 3, 2)\n",
    "        self.iconv3     = conv(filters[1] + 512, 512, 3, 1)\n",
    "        self.upconv2    = upconv(512, 256, 3, 2)\n",
    "        self.iconv2     = conv(filters[0] + 256, 256, 3, 1)\n",
    "\n",
    "\t    # Feature Fusion Block\n",
    "        self.side3          = upconv_like(1024, fusion_out_ch, 3)\n",
    "        self.side2          = upconv_like(512, fusion_out_ch, 3)\n",
    "        self.side1          = conv(256, fusion_out_ch, 1, 1)\n",
    "        self.fusion_conv    = nn.Conv2d(3*fusion_out_ch,fusion_out_ch,1)\n",
    "\n",
    "        # Cross Norm. Layer\n",
    "        self.fusion_pn = PositionwiseNorm2()\n",
    "        self.fusion_cn = ChannelwiseNorm(fusion_out_ch)\n",
    "        self.fuse_weight_fusion_1 = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
    "        self.fuse_weight_fusion_2 = torch.nn.Parameter(torch.FloatTensor(1), requires_grad=True)\n",
    "        self.fuse_weight_fusion_1.data.fill_(0.7)\n",
    "        self.fuse_weight_fusion_2.data.fill_(0.3)\n",
    "\n",
    "        self.out_channels = 192\n",
    "\n",
    "    def name(self):\n",
    "        return 'ResUNet_F2R'\n",
    "        \n",
    "    def skipconnect(self, x1, x2):\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2))\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Encoder\n",
    "        x       = self.firstrelu(self.firstbn(self.firstconv(x)))\n",
    "        x_first = self.firstmaxpool(x)\n",
    "        \n",
    "        x1 = self.layer1(x_first)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "\n",
    "        # Decoder\n",
    "        x   = self.upconv3(x3)\n",
    "        x   = self.skipconnect(x2, x)\n",
    "        x2d = self.iconv3(x)\n",
    "\n",
    "        x = self.upconv2(x2d)\n",
    "        x = self.skipconnect(x1, x)\n",
    "        x = self.iconv2(x)\n",
    "\n",
    "        # Feature Fusion output\n",
    "        d1          = self.side1(x)\n",
    "        d2          = self.side2(x2d, d1)\n",
    "        d3          = self.side3(x3, d1)\n",
    "        x_fusion    = self.fusion_conv(torch.cat((d1,d2,d3),1))  # H/4\n",
    "        \n",
    "        del x, x2, d1, d2, d3, x2d\n",
    "\n",
    "        # Shared Coupling-bridge Normalization\n",
    "        desc1       = self.fusion_pn(x_fusion)\n",
    "        desc2       = self.fusion_cn(x_fusion)\n",
    "        x_fusion_cn = desc1 * (self.fuse_weight_fusion_1/(self.fuse_weight_fusion_1+self.fuse_weight_fusion_2)) + \\\n",
    "            desc2 * (self.fuse_weight_fusion_2/(self.fuse_weight_fusion_1+self.fuse_weight_fusion_2))\n",
    "\n",
    "        return {\n",
    "            'global_map':       x3,             # Coarse level\n",
    "            'desc_map':         x_fusion,       # D_desc\n",
    "            'local_map':        x_fusion_cn,    # F_cn\n",
    "            'local_map_first':  x_first         # Initial feature maps\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705c5ea-621e-4007-9403-5761088077ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
