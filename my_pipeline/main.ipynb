{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71995697-c4ca-4c99-99c3-d74515600429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import shutil\n",
    "import logging\n",
    "import yaml\n",
    "import importlib\n",
    "import time\n",
    "from path import Path\n",
    "from abc import ABC, abstractmethod\n",
    "from PIL import Image as Im\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from matplotlib import cm\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from dataloader import aachen_loader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from feature_descriptors import backbone\n",
    "from feature_descriptors import detection_net\n",
    "# from feature_descriptors import my_model\n",
    "\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d4a112-1d12-4daf-bc6e-250058e3fd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.293] global shadow_sift.hpp:13 SIFT_create DEPRECATED: cv.xfeatures2d.SIFT_create() is deprecated due SIFT tranfer to the main repository. https://github.com/opencv/opencv/issues/16736\n"
     ]
    }
   ],
   "source": [
    "aachen_dataset = aachen_loader.Aachen_Day_Night()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2590410a-7d3b-4c5c-99db-53f6031a8246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1600, 1056])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aachen_dataset[1]['im1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a5e0955-95cf-4bc9-a6bf-f058ed32752e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1600, 1056])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aachen_dataset[3]['im1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9dd45c79-2777-4809-bd14-e171fa31d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(self, batch, _use_shared_memory=True):\n",
    "        \"\"\"Puts each data field into a tensor with outer dimension batch size.\n",
    "        Copied from https://github.com/pytorch in torch/utils/data/_utils/collate.py\n",
    "        \"\"\"\n",
    "        import re\n",
    "        error_msg = \"batch must contain tensors, numbers, dicts or lists; found {}\"\n",
    "        elem_type = type(batch[0])\n",
    "        if isinstance(batch[0], torch.Tensor):\n",
    "            out = None\n",
    "            if _use_shared_memory:\n",
    "                # If we're in a background process, concatenate directly into a\n",
    "                # shared memory tensor to avoid an extra copy\n",
    "                numel = sum([x.numel() for x in batch])\n",
    "                storage = batch[0].storage()._new_shared(numel)\n",
    "                out = batch[0].new(storage)\n",
    "            return torch.stack(batch, 0, out=out)\n",
    "        elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \\\n",
    "                and elem_type.__name__ != 'string_':\n",
    "            elem = batch[0]\n",
    "            assert elem_type.__name__ == 'ndarray'\n",
    "            # array of string classes and object\n",
    "            if re.search('[SaUO]', elem.dtype.str) is not None:\n",
    "                raise TypeError(error_msg.format(elem.dtype))\n",
    "            batch = [torch.from_numpy(b) for b in batch]\n",
    "            try:\n",
    "                return torch.stack(batch, 0)\n",
    "            except RuntimeError:\n",
    "                return batch\n",
    "        elif batch[0] is None:\n",
    "            return list(batch)\n",
    "        elif isinstance(batch[0], int):\n",
    "            return torch.LongTensor(batch)\n",
    "        elif isinstance(batch[0], float):\n",
    "            return torch.DoubleTensor(batch)\n",
    "        elif isinstance(batch[0], str):\n",
    "            return batch\n",
    "        elif isinstance(batch[0], dict):\n",
    "            return {key: self.my_collate([d[key] for d in batch]) for key in batch[0]}\n",
    "        elif isinstance(batch[0], (tuple,list)):\n",
    "            transposed = zip(*batch)\n",
    "            return [self.my_collate(samples) for samples in transposed]\n",
    "\n",
    "        raise TypeError((error_msg.format(type(batch[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "43d37495-ef51-4af9-b526-ec4e8de29e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aachen_dataloader = DataLoader(\n",
    "    aachen_dataset,\n",
    "    batch_size = 2,\n",
    "    shuffle = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6f61db97-3700-4384-9534-a1157f3b2b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3856"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aachen_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a112d7a4-a236-403e-ab1e-0bb11915a3e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 1056, 1600] at entry 0 and [3, 1600, 1056] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(aachen_dataloader):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mim1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 1056, 1600] at entry 0 and [3, 1600, 1056] at entry 1"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(aachen_dataloader):\n",
    "    print(batch['im1'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4915872f-36ef-4eec-b1a1-1182c92c0bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da6f6331-3dd9-49fe-baa7-0f58413ae93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = backbone.ResUNet_F2R().to(\"cuda\")\n",
    "net2 = detection_net.DetNet(net1, 128).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd552e99-9e2c-4a54-8ca2-bdd7f729bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opencv_rainbow(resolution=1000):\n",
    "    # Construct the opencv equivalent of Rainbow\n",
    "    opencv_rainbow_data = (\n",
    "        (0.000, (1.00, 0.00, 0.00)),\n",
    "        (0.400, (1.00, 1.00, 0.00)),\n",
    "        (0.600, (0.00, 1.00, 0.00)),\n",
    "        (0.800, (0.00, 0.00, 1.00)),\n",
    "        (1.000, (0.60, 0.00, 1.00))\n",
    "    )\n",
    "\n",
    "    return LinearSegmentedColormap.from_list('opencv_rainbow', opencv_rainbow_data, resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad17c670-42dd-4565-999b-f5fc72ad99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_res_colormap(low_res_cmap, resolution=1000, max_value=1):\n",
    "    # Construct the list colormap, with interpolated values for higer resolution\n",
    "    # For a linear segmented colormap, you can just specify the number of point in\n",
    "    # cm.get_cmap(name, lutsize) with the parameter lutsize\n",
    "    x = np.linspace(0, 1, low_res_cmap.N)\n",
    "    low_res = low_res_cmap(x)\n",
    "    new_x = np.linspace(0, max_value, resolution)\n",
    "    high_res = np.stack([np.interp(new_x, x, low_res[:, i]) for i in range(low_res.shape[1])], axis=1)\n",
    "    return ListedColormap(high_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2654af92-0b74-4794-95f5-3dd1ee42770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68907/3076831541.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  'magma': high_res_colormap(cm.get_cmap('magma')),\n",
      "/tmp/ipykernel_68907/3076831541.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  'bone': cm.get_cmap('bone', 10000)}\n"
     ]
    }
   ],
   "source": [
    "COLORMAPS = {'rainbow': opencv_rainbow(),\n",
    "             'magma': high_res_colormap(cm.get_cmap('magma')),\n",
    "             'bone': cm.get_cmap('bone', 10000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ad7bc49-ea14-4783-b551-92a9e086df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2array(tensor, max_value=None, colormap='rainbow'):\n",
    "    tensor = tensor.detach().cpu()\n",
    "    if max_value is None:\n",
    "        max_value = tensor[tensor < np.inf].max().item()\n",
    "    if tensor.ndimension() == 2 or tensor.size(0) == 1:\n",
    "        norm_array = tensor.squeeze().numpy()/max_value\n",
    "        norm_array[norm_array == np.inf] = np.nan\n",
    "        array = COLORMAPS[colormap](norm_array).astype(np.float32)\n",
    "        array = array.transpose(2, 0, 1)[:3]\n",
    "\n",
    "    elif tensor.ndimension() == 3:\n",
    "        assert(tensor.size(0) == 3)\n",
    "        array = 0.5 + tensor.numpy()*0.5\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37711ec4-1281-4007-80d2-d4fa2abc72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_desc(inputs, outputs, processed, multiscale=False):\n",
    "        kpt         = processed['kpt']\n",
    "        feat_f      = processed['desc']\n",
    "        kp_score    = processed['kp_score']\n",
    "\n",
    "        name = inputs['name1'][0]#.replace('ppm','wsf')\n",
    "        save_path = self.desc_root/name\n",
    "        \n",
    "        if not save_path.dirname().exists():\n",
    "            save_path.dirname().makedirs_p()\n",
    "\n",
    "        message = \"\\nkpts: {}\".format(kpt.shape[0])\n",
    "\n",
    "        desc = None\n",
    "        if multiscale:\n",
    "            desc = feat_f\n",
    "        else:\n",
    "            desc = feat_f.squeeze(0).detach().cpu().numpy()\n",
    "        scores = kp_score.squeeze(0).detach().cpu().numpy()\n",
    "        with open(save_path + '.{}'.format('postfix'), 'wb') as output_file:\n",
    "            np.savez(output_file, keypoints=kpt, scores=scores, descriptors=desc)\n",
    "\n",
    "        return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d65a099-672c-49f8-b7fc-938cc41b0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.distributions import Categorical, Bernoulli\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def homogenize(coord):\n",
    "    coord = torch.cat((coord, torch.ones_like(coord[..., [0]])), -1)\n",
    "    return coord\n",
    "\n",
    "def normalize_coords(coord, h, w):\n",
    "    '''\n",
    "    turn the coordinates from pixel indices to the range of [-1, 1]\n",
    "    :param coord: [..., 2]\n",
    "    :param h: the image height\n",
    "    :param w: the image width\n",
    "    :return: the normalized coordinates [..., 2]\n",
    "    '''\n",
    "    c = torch.Tensor([(w - 1) / 2., (h - 1) / 2.]).to(coord.device).float()\n",
    "    # print(coord[:,:,0].max(), coord[:,:,1].max(), w, h)\n",
    "    coord_norm = (coord - c) / c\n",
    "    # print(coord_norm[:,:,0].max(), coord_norm[:,:,1].max(), coord_norm[:,:,0].min(), coord_norm[:,:,1].min())\n",
    "    return coord_norm\n",
    "\n",
    "def denormalize_coords(coord_norm, h, w):\n",
    "    '''\n",
    "    turn the coordinates from normalized value ([-1, 1]) to actual pixel indices\n",
    "    :param coord_norm: [..., 2]\n",
    "    :param h: the image height\n",
    "    :param w: the image width\n",
    "    :return: actual pixel coordinates\n",
    "    '''\n",
    "    c = torch.Tensor([(w - 1) / 2., (h - 1) / 2.]).to(coord_norm.device)\n",
    "    coord = coord_norm * c + c\n",
    "    return coord\n",
    "\n",
    "def sample_feat_by_coord(x, coord_n, norm=False):\n",
    "    '''\n",
    "    sample from normalized coordinates\n",
    "    :param x: feature map [batch_size, n_dim, h, w]\n",
    "    :param coord_n: normalized coordinates, [batch_size, n_pts, 2]\n",
    "    :param norm: if l2 normalize features\n",
    "    :return: the extracted features, [batch_size, n_pts, n_dim]\n",
    "    '''\n",
    "    print(\"coord_n \", coord_n.shape)\n",
    "    # print(\"x \", x.shape)\n",
    "    feat = F.grid_sample(x, coord_n.unsqueeze(2), padding_mode='zeros', align_corners=False).squeeze(-1)\n",
    "    # print(\"feat \", feat.shape)\n",
    "    if norm:\n",
    "        feat = F.normalize(feat, p=2, dim=1)\n",
    "        # print(\"featnorm \", feat.shape)\n",
    "    feat = feat.transpose(1, 2)\n",
    "    # print(\"featnorm transpose\", feat.shape)\n",
    "    return feat\n",
    "\n",
    "def get_expected_correspondence_locs(feat1, featmap2, with_std=False, flag=False):\n",
    "    '''\n",
    "    compute the expected correspondence locations\n",
    "    :param feat1: the feature vectors of query points [batch_size, n_pts, n_dim]\n",
    "    :param featmap2: the feature maps of the reference image [batch_size, n_dim, h, w]\n",
    "    :param with_std: if return the standard deviation\n",
    "    :return: the normalized expected correspondence locations [batch_size, n_pts, 2]\n",
    "    '''\n",
    "    B, d, h2, w2 = featmap2.size()\n",
    "    grid_n = gen_grid(-1, 1, -1, 1, h2, w2).to(featmap2.device)\n",
    "    featmap2_flatten = featmap2.reshape(B, d, h2*w2).transpose(1, 2)  # BX(hw)xd\n",
    "    prob = compute_prob(feat1, featmap2_flatten)  # Bxnx(hw)\n",
    "\n",
    "    grid_n = grid_n.unsqueeze(0).unsqueeze(0)  # 1x1x(hw)x2\n",
    "    expected_coord_n = torch.sum(grid_n * prob.unsqueeze(-1), dim=2)  # Bxnx2\n",
    "\n",
    "    if with_std:\n",
    "        # convert to normalized scale [-1, 1]\n",
    "        var = torch.sum(grid_n**2 * prob.unsqueeze(-1), dim=2) - expected_coord_n**2  # Bxnx2\n",
    "        std = torch.sum(torch.sqrt(torch.clamp(var, min=1e-10)), -1)  # Bxn\n",
    "        # var_prob = (prob-prob.mean(-1,True)).square().sum(-1,True)/prob.shape[-1] # Bxnx1\n",
    "        # kurtosis = torch.pow(prob-prob.mean(-1,True),4).sum(-1,True)/(prob.shape[2]*var_prob**2)\n",
    "        if flag == True:\n",
    "            kurtosis = torch.pow(grid_n-expected_coord_n.unsqueeze(-2), 4).mean(-2)/torch.pow(var, 2)\n",
    "            kurtosis = (kurtosis/10.).clamp(0,1)\n",
    "            # kurtosis = var\n",
    "            return expected_coord_n, std, kurtosis.mean(-1), prob#, var_prob\n",
    "        else:\n",
    "            return expected_coord_n, std\n",
    "    else:\n",
    "        return expected_coord_n\n",
    "\n",
    "def gen_grid(h_min, h_max, w_min, w_max, len_h, len_w):\n",
    "    x, y = torch.meshgrid([torch.linspace(w_min, w_max, len_w), torch.linspace(h_min, h_max, len_h)])\n",
    "    grid = torch.stack((x, y), -1).transpose(0, 1).reshape(-1, 2).float()\n",
    "    return grid\n",
    "\n",
    "def compute_prob(feat1, feat2, loss_distance='cos', with_scale=False, return_sim=False):\n",
    "    '''\n",
    "    compute probability\n",
    "    :param feat1: query features, [batch_size, m, n_dim]\n",
    "    :param feat2: reference features, [batch_size, n, n_dim]\n",
    "    :return: probability, [batch_size, m, n]\n",
    "    '''\n",
    "    assert loss_distance in ['cos', 'euc']\n",
    "    if return_sim:\n",
    "        assert loss_distance=='cos'\n",
    "    if loss_distance == 'cos':\n",
    "        sim = feat1.bmm(feat2.transpose(1, 2))\n",
    "        if with_scale:\n",
    "            scale = sim.new_tensor(feat2.shape[1])\n",
    "            scale = scale.sqrt()\n",
    "        else:\n",
    "            scale = 1\n",
    "        prob = F.softmax(scale*sim, dim=-1)  # Bxmxn\n",
    "    else:\n",
    "        dist = torch.sum(feat1**2, dim=-1, keepdim=True) + \\\n",
    "               torch.sum(feat2**2, dim=-1, keepdim=True).transpose(1, 2) - \\\n",
    "               2 * feat1.bmm(feat2.transpose(1, 2))\n",
    "        prob = F.softmax(-dist, dim=-1)  # Bxmxn\n",
    "    if return_sim:\n",
    "        return prob, sim\n",
    "    else:\n",
    "        return prob\n",
    "\n",
    "def Dual_Softmax(costs, iters=None, temperature=None):\n",
    "    '''\n",
    "    find the correspondece with sinkhorn algorithm\n",
    "    :param costs: [b, m, n]\n",
    "    :param iters: the number of iterations\n",
    "    :return: the optimized scores [b,m,n]\n",
    "    '''\n",
    "    b, m, n = costs.shape\n",
    "    # scale = max(m,n)\n",
    "    scale = 1\n",
    "    if temperature is None:\n",
    "        costs_input = - 15 * scale * costs\n",
    "    else:\n",
    "        costs_input = - temperature * scale * costs\n",
    "    prob_col = F.softmax(costs_input, dim=2)\n",
    "    prob_row = F.softmax(costs_input, dim=1)\n",
    "    prob = prob_col*prob_col\n",
    "\n",
    "    return prob, None\n",
    "\n",
    "def generate_kpts(inputs, outputs, nms_radius, num_pts=False, stable_prob=0.9, use_nms=True, stride=1):\n",
    "    \"\"\"\n",
    "    generate keypoints on the entire image\n",
    "    \"\"\"\n",
    "    preds1 = outputs['preds1']\n",
    "    preds2 = outputs['preds2']\n",
    "    kp_map1, kp_map2 = preds1['local_point'], preds2['local_point']\n",
    "\n",
    "    if torch.rand(1)<stable_prob: # stable select\n",
    "        kps1, kp_score1 = generate_kpts_single(kp_map1, nms_radius, num_pts, scale=4, stride=stride, use_nms=use_nms)\n",
    "        kps2, kp_score2 = generate_kpts_single(kp_map2, nms_radius, num_pts, scale=4, stride=stride, use_nms=use_nms)\n",
    "    else: # random select\n",
    "        temperature = 0.01/(outputs['epoch']+1)\n",
    "        kps1, kp_score1 = generate_kpts_single(kp_map1, nms_radius, num_pts, scale=4, \n",
    "            stable=False, temperature=temperature, stride=stride, use_nms=use_nms)\n",
    "        kps2, kp_score2 = generate_kpts_single(kp_map2, nms_radius, num_pts, scale=4, \n",
    "            stable=False, temperature=temperature, stride=stride, use_nms=use_nms)\n",
    "    return kps1, kps2, kp_score1, kp_score2\n",
    "\n",
    "def generate_kpts_single(kp_map, nms_radius, num_pts=False, scale=4, stable=True, temperature=1, stride=1, use_nms=True, thr=False, thr_mod='mean'):\n",
    "    b, _, h, w = kp_map.shape\n",
    "    grids_org = gen_grid(h_min=-1, h_max=1, w_min=-1, w_max=1, len_h=h, len_w=w)\n",
    "    grids_org = grids_org.reshape(h, w, 2)[None, :, :, :].repeat(b, 1, 1, 1).to(kp_map)\n",
    "    grids_org = grids_org.permute(0,3,1,2) # bx2xhxw\n",
    "\n",
    "    # nms omits the boarder pixels of the original score map \n",
    "    # so that the mask size will be the same as processed score map\n",
    "    if use_nms == 'softnms': # softnms for softnms\n",
    "        nms_mask = soft_nms(kp_map[:,:,1:-1,1:-1], nms_radius)\n",
    "    elif use_nms: # True for hard nms\n",
    "        nms_mask = nms(kp_map[:,:,1:-1,1:-1], nms_radius) \n",
    "    elif not use_nms: # False for no nms\n",
    "        nms_mask = torch.ones((b,1,h-2,w-2)).to(kp_map)\n",
    "\n",
    "    if thr :\n",
    "        if thr_mod == 'max':\n",
    "            kp_thr = (kp_map[:,:,1:-1,1:-1]).reshape(b,1,-1).max(2)[0]\n",
    "        elif thr_mod == 'mean':\n",
    "            kp_thr = (kp_map[:,:,1:-1,1:-1]).reshape(b,1,-1).mean(2)\n",
    "        elif thr_mod == 'abs':\n",
    "            kp_thr = torch.tensor(1.).to(kp_map).repeat(b)\n",
    "        # print(torch.max(kp_map),torch.mean(kp_map), torch.min(kp_map))\n",
    "        thr_mask = kp_map[:,:,1:-1,1:-1]>thr*kp_thr.view(b,1,1,1)\n",
    "        nms_mask = thr_mask*nms_mask\n",
    "\n",
    "    # process the score map and grids\n",
    "    grids = kp_map*grids_org\n",
    "    grids = F.avg_pool2d(grids, 3, stride=stride, padding=0)\n",
    "    kp_weight = F.avg_pool2d(kp_map, 3, stride=stride, padding=0)\n",
    "    grids = grids/kp_weight\n",
    "    kp_score_map = F.max_pool2d(kp_map, 3, stride=stride, padding=0)\n",
    "\n",
    "    if not num_pts:\n",
    "        if use_nms != 'softnms':\n",
    "            num_pts = (nms_mask.view(b,-1).sum(1).min()).int()\n",
    "        else:\n",
    "            # num_pts = (((nms_mask*kp_map[:,:,1:-1,1:-1]).view(b,-1)>thr*((nms_mask*kp_map[:,:,1:-1,1:-1]).view(b,-1).mean(1, True))).sum(1).min()).int()\n",
    "            num_pts = (thr_mask.view(b,-1).sum(1).min()).int()\n",
    "    else:\n",
    "        if use_nms != 'softnms' and num_pts>nms_mask.view(b,-1).sum(1).min():\n",
    "            num_pts = (nms_mask.view(b,-1).sum(1).min()).int()\n",
    "        if use_nms == 'softnms' and num_pts>thr_mask.view(b,-1).sum(1).min():\n",
    "            num_pts = (thr_mask.view(b,-1).sum(1).min()).int()\n",
    "    if num_pts < 128:\n",
    "        num_pts = 128\n",
    "\n",
    "    if stable:\n",
    "        _, idx = (nms_mask*kp_map[:,:,1:-1,1:-1]).permute(0,2,3,1).contiguous().view(b,-1).topk(num_pts)\n",
    "\n",
    "        kps = grids.permute(0,2,3,1).view(b,-1,2).gather(dim=1,index=idx.unsqueeze(-1).repeat(1,1,2))\n",
    "        kp_score = kp_score_map.permute(0,2,3,1).view(b,-1,1).gather(dim=1,index=idx.unsqueeze(-1))\n",
    "    else:\n",
    "        select = gumbel_softmax(nms_mask*kp_map[:,:,1:-1,1:-1], num_pts, temperature) # bxnxhw\n",
    "\n",
    "        kps = select@grids.permute(0,2,3,1).reshape(b,(h-2)*(w-2),2)\n",
    "        kp_score = select@kp_map[:,:,1:-1,1:-1].permute(0,2,3,1).reshape(b,(h-2)*(w-2),1)\n",
    "\n",
    "    return kps, kp_score\n",
    "\n",
    "def generate_kpts_single_noavg(kp_map, nms_radius, num_pts=False, scale=4, stable=True, temperature=1, stride=1, use_nms=True, thr=False, thr_mod='mean'):\n",
    "    b, _, h, w = kp_map.shape\n",
    "    grids_org = gen_grid(h_min=-1, h_max=1, w_min=-1, w_max=1, len_h=h, len_w=w)\n",
    "    # h, w = scale*h, scale*w\n",
    "    # grids_org = gen_grid(h_min=0, h_max=h-1, w_min=0, w_max=w-1, len_h=h, len_w=w)\n",
    "    grids_org = grids_org.reshape(h, w, 2)[None, :, :, :].repeat(b, 1, 1, 1).to(kp_map)\n",
    "    grids_org = grids_org.permute(0,3,1,2) # bx2xhxw\n",
    "\n",
    "    # nms omits the boarder pixels of the original score map \n",
    "    # so that the mask size will be the same as processed score map\n",
    "    if use_nms == 'softnms': # softnms for softnms\n",
    "        nms_mask = soft_nms(kp_map, nms_radius)\n",
    "    elif use_nms: # True for hard nms\n",
    "        nms_mask = nms(kp_map, nms_radius) \n",
    "    elif not use_nms: # False for no nms\n",
    "        nms_mask = torch.ones((b,1,h,w)).to(kp_map)\n",
    "\n",
    "    if thr :\n",
    "        if thr_mod == 'max':\n",
    "            kp_thr = (kp_map).reshape(b,1,-1).max(2)[0]\n",
    "        elif thr_mod == 'mean':\n",
    "            kp_thr = (kp_map).reshape(b,1,-1).mean(2)\n",
    "        thr_mask = kp_map>thr*kp_thr.view(b,1,1,1)\n",
    "        nms_mask = thr_mask*nms_mask\n",
    "\n",
    "    grids = grids_org\n",
    "\n",
    "    if not num_pts:\n",
    "        if use_nms != 'softnms':\n",
    "            num_pts = (nms_mask.view(b,-1).sum(1).min()).int()\n",
    "        else:\n",
    "            # num_pts = (((nms_mask*kp_map[:,:,1:-1,1:-1]).view(b,-1)>thr*((nms_mask*kp_map[:,:,1:-1,1:-1]).view(b,-1).mean(1, True))).sum(1).min()).int()\n",
    "            num_pts = (thr_mask.view(b,-1).sum(1).min()).int()\n",
    "    else:\n",
    "        if use_nms != 'softnms' and num_pts>nms_mask.view(b,-1).sum(1).min():\n",
    "            num_pts = (nms_mask.view(b,-1).sum(1).min()).int()\n",
    "        if use_nms == 'softnms' and num_pts>thr_mask.view(b,-1).sum(1).min():\n",
    "            num_pts = (thr_mask.view(b,-1).sum(1).min()).int()\n",
    "    if num_pts < 128:\n",
    "        num_pts = 128\n",
    "\n",
    "    if stable:\n",
    "        _, idx = (nms_mask*kp_map).permute(0,2,3,1).contiguous().view(b,-1).topk(num_pts)\n",
    "\n",
    "        kps = grids.permute(0,2,3,1).view(b,-1,2).gather(dim=1,index=idx.unsqueeze(-1).repeat(1,1,2))\n",
    "        kp_score = kp_map.permute(0,2,3,1).view(b,-1,1).gather(dim=1,index=idx.unsqueeze(-1))\n",
    "    else:\n",
    "        select = gumbel_softmax(nms_mask*kp_map, num_pts, temperature) # bxnxhw\n",
    "\n",
    "        kps = select@grids.permute(0,2,3,1).reshape(b,(h-2)*(w-2),2)\n",
    "        kp_score = select@kp_map.permute(0,2,3,1).reshape(b,(h-2)*(w-2),1)\n",
    "\n",
    "    return kps, kp_score\n",
    "\n",
    "def unfold(tensor, grid_size, stride=None):\n",
    "    if stride is None:\n",
    "        stride = grid_size\n",
    "    unfold_tensor = tensor.unfold(2, grid_size, stride).unfold(3, grid_size, stride)\n",
    "    b,c,h,w,g1,g2 = unfold_tensor.shape\n",
    "    unfold_tensor = unfold_tensor.reshape(b,c,h,w,g1*g2)\n",
    "    return unfold_tensor\n",
    "\n",
    "def regular_sample(tensor):\n",
    "    b,c,h,w,g = tensor.shape \n",
    "    idx = torch.multinomial(tensor.reshape(-1,g), 1)\n",
    "    idx = idx.reshape(b,c,h,w,1)\n",
    "    return idx\n",
    "\n",
    "def generate_kpts_regular_grid(inputs, outputs, grid_size, num_pts=False, stable_prob=0.9, use_nms=True, nms_radius=None):\n",
    "    preds1 = outputs['preds1']\n",
    "    preds2 = outputs['preds2']\n",
    "    kp_map1, kp_map2 = preds1['local_point'], preds2['local_point']\n",
    "\n",
    "    if torch.rand(1)<stable_prob: # stable select\n",
    "        kps1, kp_score1 = generate_kpts_regular_grid_single(kp_map1, grid_size, num_pts, scale=4, stable=True, use_nms=use_nms, \n",
    "            nms_radius=nms_radius)\n",
    "        kps2, kp_score2 = generate_kpts_regular_grid_single(kp_map2, grid_size, num_pts, scale=4, stable=True, use_nms=use_nms, \n",
    "            nms_radius=nms_radius)\n",
    "    else: # random select\n",
    "        kps1, kp_score1 = generate_kpts_regular_grid_single(kp_map1, grid_size, num_pts, scale=4, stable=False, use_nms=use_nms, \n",
    "            nms_radius=nms_radius)\n",
    "        kps2, kp_score2 = generate_kpts_regular_grid_single(kp_map2, grid_size, num_pts, scale=4, stable=False, use_nms=use_nms, \n",
    "            nms_radius=nms_radius)\n",
    "    return kps1, kps2, kp_score1, kp_score2\n",
    "\n",
    "def generate_kpts_regular_grid_single(kp_map, grid_size, num_pts=False, scale=4, stable=True, use_nms=True, nms_radius=None, thr=None, thr_mod='mean'):\n",
    "    b, _, h, w = kp_map.shape\n",
    "    grids_org = gen_grid(h_min=-1, h_max=1, w_min=-1, w_max=1, len_h=h, len_w=w)\n",
    "    # h, w = scale*h, scale*w\n",
    "    # grids_org = gen_grid(h_min=0, h_max=h-1, w_min=0, w_max=w-1, len_h=h, len_w=w)\n",
    "    grids_org = grids_org.reshape(h, w, 2)[None, :, :, :].repeat(b, 1, 1, 1).to(kp_map)\n",
    "    grids_org = grids_org.permute(0,3,1,2) # bx2xhxw\n",
    "    if use_nms == 'softnms':\n",
    "        soft_mask = soft_nms(kp_map, nms_radius)\n",
    "        kp_map = soft_mask*kp_map\n",
    "        nms_mask = torch.ones_like(soft_mask).bool()\n",
    "    elif use_nms:\n",
    "        nms_mask = nms(kp_map, nms_radius)\n",
    "    else:\n",
    "        nms_mask = torch.ones_like(kp_map).bool()\n",
    "\n",
    "    if thr is not None:\n",
    "        if thr_mod == 'max':\n",
    "            kp_thr = kp_map.view(b,1,-1).max(2)[0]\n",
    "        elif thr_mod == 'mean':\n",
    "            kp_thr = kp_map.view(b,1,-1).mean(2)\n",
    "        thr_mask = kp_map>thr*kp_thr.view(b,1,1,1)\n",
    "        nms_mask = thr_mask&nms_mask\n",
    "\n",
    "    grids_unfold = unfold(grids_org, grid_size)\n",
    "    kpmap_unfold = unfold(kp_map, grid_size) \n",
    "    nms_unfold = unfold(nms_mask, grid_size)\n",
    "\n",
    "    kpmap_unfold_n = F.softmax(kpmap_unfold, dim=4)\n",
    "    if stable:\n",
    "        idx = kpmap_unfold_n.argmax(-1,True)\n",
    "    else:\n",
    "        idx = regular_sample(kpmap_unfold_n)\n",
    "\n",
    "    kps = grids_unfold.gather(dim=4, index=idx.repeat(1,2,1,1,1)) # bx2x(h//g)x(w//g)x1\n",
    "    kp_score = kpmap_unfold.gather(dim=4, index=idx) # bx1x(h//g)x(w//g)x1\n",
    "    mask = nms_unfold.gather(dim=4, index=idx) # bx1x(h//g)x(w//g)x1\n",
    "\n",
    "    kps = kps.reshape(b,2,-1).transpose(1,2) # bxnx2\n",
    "    kp_score = kp_score.reshape(b,1,-1).transpose(1,2) # bxnx1\n",
    "    mask = mask.reshape(b,1,-1).transpose(1,2) # bxnx1\n",
    "\n",
    "    if num_pts:\n",
    "        if num_pts > mask.sum(1).min():\n",
    "            num_pts=mask.sum(1).min()\n",
    "        kp_score, top_idx = (mask*kp_score).topk(num_pts, dim=1)\n",
    "        kps = kps.gather(dim=1, index=top_idx)\n",
    "    else:\n",
    "        if use_nms :\n",
    "            num_pts=mask.sum(1).min()\n",
    "            if num_pts < 128:\n",
    "                num_pts = 128\n",
    "            kp_score, top_idx = (mask*kp_score).topk(num_pts, dim=1)\n",
    "            kps = kps.gather(dim=1, index=top_idx.repeat(1,1,2))\n",
    "    return kps, kp_score\n",
    "\n",
    "def soft_nms(score, patch_radius):\n",
    "    b,c,h,w = score.shape\n",
    "    window_size = 2*patch_radius + 1\n",
    "    padding_size = patch_radius\n",
    "\n",
    "    score = score.detach().contiguous()\n",
    "    # max_per_sample = torch.max(score.view(b,-1), dim=1)[0]\n",
    "    # score = score/max_per_sample.view(b,1,1,1)\n",
    "    # score = score.detach()\n",
    "\n",
    "    alpha_input = score - F.avg_pool2d(\n",
    "                F.pad(score, [padding_size]*4, mode='reflect'),\n",
    "                window_size, stride=1\n",
    "                )\n",
    "    alpha = F.softplus(alpha_input)\n",
    "\n",
    "    return alpha\n",
    "\n",
    "def nms(score, patch_radius):\n",
    "    patch_size = 2*patch_radius+1\n",
    "    score_pad = F.pad(score.detach(), (patch_radius, patch_radius, patch_radius, patch_radius), mode='reflect')\n",
    "    # max_score = F.max_pool2d(score_pad, patch_size, stride=1, padding=0)\n",
    "    # mask = score==max_score\n",
    "\n",
    "    _, idx = F.max_pool2d(score_pad, patch_size, stride=1, padding=0, return_indices=True)\n",
    "    # if len(idx.shape) == 4:\n",
    "    #     assert idx.shape[0] == 1\n",
    "    #     idx = idx.squeeze(0)\n",
    "    b,_, h, w = score.shape\n",
    "    coords = torch.arange((h+2*patch_radius) * (w+2*patch_radius), device=score.device)\\\n",
    "        .reshape(1, 1, h+2*patch_radius, w+2*patch_radius).repeat(b,1,1,1)\n",
    "    coords = coords[:,:,patch_radius:-patch_radius,patch_radius:-patch_radius]\n",
    "    mask = idx == coords\n",
    "    return mask\n",
    "\n",
    "\n",
    "    # print(mask.view(score.shape[0],-1).sum(1))\n",
    "    # return mask\n",
    "\n",
    "def gumbel_noise(shape, eps=1e-20):\n",
    "    U = torch.rand(shape)\n",
    "    U = U.cuda()\n",
    "    return -torch.log(-torch.log(U + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(prob, num_points, temperature=1):\n",
    "    b, one, h, w = prob.shape\n",
    "    y = prob.view(b,1,h*w).repeat(1, num_points, 1) + gumbel_noise((b, num_points, h*w))\n",
    "    one_hot_soft = F.softmax(y/temperature, dim=2)\n",
    "    return one_hot_soft\n",
    "\n",
    "def gumbel_softmax(prob, num_points, temperature=1, hard=False):\n",
    "    one_hot_soft = gumbel_softmax_sample(prob, num_points, temperature) # bx1xhw\n",
    "    if not hard:\n",
    "        return one_hot_soft\n",
    "    b, num, hw = one_hot_soft.shape\n",
    "    _, idx = one_hot_soft.max(dim=2)\n",
    "    one_hot = torch.zeros_like(one_hot_soft).view(-1, hw)\n",
    "    one_hot.scatter(dim=2, index=idx.view(-1, 1), src=1)\n",
    "    one_hot = one_hot.view(b, num, hw)\n",
    "    one_hot = (one_hot - one_hot_soft).detach() + one_hot\n",
    "    return one_hot\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_points(epipolar_line, im_size, linelen_thr):\n",
    "    '''\n",
    "    this function is actually the same as get_endpoints\n",
    "    return endpoints1 endpoints2 bxnx2\n",
    "    return valid bxn\n",
    "    '''\n",
    "    batch_size, _, n_pts = epipolar_line.shape\n",
    "    h, w = im_size\n",
    "    a = epipolar_line[:,0,:] #Bxn\n",
    "    b = epipolar_line[:,1,:]\n",
    "    c = epipolar_line[:,2,:]\n",
    "    point_l = torch.stack([torch.zeros_like(a), -c/b], -1) #Bxnx2\n",
    "    point_r = torch.stack([(w-1)*torch.ones_like(a), -(a*(w-1)+c)/b], -1)\n",
    "    point_u = torch.stack([-(b*(h-1)+c)/a, (h-1)*torch.ones_like(a)], -1)\n",
    "    point_b = torch.stack([-c/a, torch.zeros_like(a)], -1)\n",
    "    points = torch.stack([point_l, point_r, point_u, point_b], -1).transpose(2,3) #Bxnx4x2\n",
    "    mask = (points[:,:,:,0]>=0) & (points[:,:,:,0]<=w-1) & (points[:,:,:,1]>=0) & (points[:,:,:,1]<=h-1) #Bxnx4\n",
    "    valid = mask.sum(-1) == 2 #Bxn\n",
    "\n",
    "    mask[~valid] = torch.tensor([True, True, False, False]).to(mask.device)\n",
    "    points = points[mask].reshape(batch_size, n_pts, 2, 2)\n",
    "    points1 = points[:,:,0,:]\n",
    "    points2 = points[:,:,1,:]\n",
    "    endpoints_1_n = normalize_coords(points1, h, w)\n",
    "    endpoints_2_n = normalize_coords(points2, h, w)\n",
    "    line_len = endpoints_2_n - endpoints_1_n\n",
    "    len_mask = (line_len**2).sum(-1).sqrt()>linelen_thr\n",
    "    valid = valid&len_mask\n",
    "\n",
    "    return valid\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_kpts_regular_grid_random(inputs, outputs, grid_size, keep_spatial=False, random_select='random'):\n",
    "    \"\"\"\n",
    "    this is the function used to generate key points within regualr grid in descriptor initialization stage\n",
    "    \"\"\"\n",
    "    preds1 = outputs['preds1']\n",
    "    preds2 = outputs['preds2']\n",
    "    \n",
    "    kp_map1, kp_map2 = torch.ones_like(preds1['local_point']), torch.ones_like(preds2['local_point'])\n",
    "\n",
    "    kps1, kp_score1 = generate_kpts_regular_grid_random_single(kp_map1, grid_size, random_select)\n",
    "    kps2, kp_score2 = generate_kpts_regular_grid_random_single(kp_map2, grid_size, random_select)\n",
    "\n",
    "    if not keep_spatial:\n",
    "        b = kps1.shape[0]\n",
    "        kps1, kps2 = kps1.reshape(b,2,-1).transpose(1,2), kps2.reshape(b,2,-1).transpose(1,2)\n",
    "        kp_score1, kp_score2 = kp_score1.reshape(b,1,-1).transpose(1,2), kp_score2.reshape(b,1,-1).transpose(1,2)\n",
    "    else:\n",
    "        kps1, kps2 = kps1.squeeze(-1).permute(0,2,3,1), kps2.squeeze(-1).permute(0,2,3,1)\n",
    "        kp_score1, kp_score2 = kp_score1.permute(0,2,3,1), kp_score2.permute(0,2,3,1)\n",
    "    return kps1, kps2, kp_score1, kp_score2\n",
    "\n",
    "def generate_kpts_regular_grid_random_single(kp_map, grid_size, random_select):\n",
    "    \"\"\"\n",
    "    note that the score returned by this function is the logp within the grid_size window\n",
    "    \"\"\"\n",
    "    b, _, h, w = kp_map.shape\n",
    "    if random_select == 'random':\n",
    "        grids_org = gen_grid(h_min=-1, h_max=1, w_min=-1, w_max=1, len_h=h, len_w=w)\n",
    "        grids_org = grids_org.reshape(h, w, 2)[None, :, :, :].repeat(b, 1, 1, 1).to(kp_map)\n",
    "        grids_org = grids_org.permute(0,3,1,2) # bx2xhxw\n",
    "        \n",
    "        kpmap_unfold = unfold(kp_map, grid_size) # bx1x(h//g)x(w//g)x(g*g)\n",
    "        proposal_dist = Categorical(logits=kpmap_unfold)\n",
    "        proposals     = proposal_dist.sample() # bx1x(h//g)x(w//g)\n",
    "        proposal_logp = proposal_dist.log_prob(proposals) # bx1x(h//g)x(w//g)\n",
    "        kp_score = torch.gather(kpmap_unfold, dim=-1, index=proposals[..., None]).squeeze(-1) # bx1x(h//g)x(w//g)\n",
    "        \n",
    "        grids_unfold = unfold(grids_org, grid_size) # bx2x(h//g)x(w//g)x(g*g)\n",
    "        kps = grids_unfold.gather(dim=4, index=proposals.unsqueeze(-1).repeat(1,2,1,1,1))\n",
    "    elif random_select == 'regular_random':\n",
    "        start = 0.5*grid_size/h\n",
    "        num_w = w//grid_size\n",
    "        num_h = h//grid_size\n",
    "        kps = gen_grid(h_min=-1+start, h_max=1-start, w_min=-1+start, w_max=1-start, len_h=num_h, len_w=num_w)\n",
    "        regular_rand = start*(2*torch.rand(b,1,1,2)-1).to(kp_map)\n",
    "        kps = kps.reshape(num_h, num_w, 2)[None, :, :, :].repeat(b, 1, 1, 1).to(kp_map) + regular_rand\n",
    "        kp_score = F.grid_sample(kp_map, kps, padding_mode='zeros', align_corners=False) # bx1x(h//g)x(w//g)\n",
    "        kps = kps.permute(0,3,1,2)\n",
    "    else:\n",
    "        start = 0.5*grid_size/h\n",
    "        num_w = w//grid_size\n",
    "        num_h = h//grid_size\n",
    "        kps = gen_grid(h_min=-1+start, h_max=1-start, w_min=-1+start, w_max=1-start, len_h=num_h, len_w=num_w)\n",
    "        kps = kps.reshape(h, w, 2)[None, :, :, :].repeat(b, 1, 1, 1).to(kp_map)\n",
    "        kp_score = F.grid_sample(kp_map, kps, padding_mode='zeros', align_corners=False) # bx1x(h//g)x(w//g)\n",
    "        kps = kps.permute(0,3,1,2) # bx2x(h//g)x(w//g)\n",
    "    return kps, kp_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def epipolar_line_search(coord, Fmat, feat1, featmap2, h, w, line_step=100, use_nn=True, loc_rand=True, window_size=0.125, visualize=False):\n",
    "    batch_size, n_dim, h2, w2 = featmap2.shape\n",
    "    n_pts = coord.shape[1]\n",
    "    endpoints_1_n, endpoints_2_n, valid=get_endpoints(coord, Fmat, h, w)\n",
    "    sample_grids = torch.stack([torch.linspace(0., 1., line_step), torch.linspace(0., 1., line_step)], -1).to(coord.device) # stepx2\n",
    "    line_len = endpoints_2_n - endpoints_1_n #bxnx2\n",
    "\n",
    "    # weight_len = (line_len[:,:,0]**2+line_len[:,:,1]**2).sqrt() #bxn decide the weight according to the epipolar line length, which belongs to [0, 2*sqrt(2)]\n",
    "    sample_grids = line_len[:,:,None,:]*sample_grids[None,None,:,:] #bxnxstepx2\n",
    "    sample_grids = sample_grids+endpoints_1_n[:,:,None,:]\n",
    "\n",
    "    sample_points = F.grid_sample(featmap2, sample_grids, padding_mode='border', align_corners=False).permute(0, 2, 3, 1)  # Bxnxstepxd\n",
    "    prob = compute_prob(feat1.reshape(batch_size*n_pts, 1, n_dim), \n",
    "                sample_points.reshape(batch_size*n_pts, line_step, n_dim)).reshape(batch_size, n_pts, line_step)\n",
    "\n",
    "    # expected_coord = torch.sum(sample_grids * prob.unsqueeze(-1), dim=2)  # Bxnx2\n",
    "    if use_nn:\n",
    "        mask = prob==prob.max(-1,True)[0]\n",
    "        expected_coord = (mask.unsqueeze(-1)*sample_grids).sum(2) # bxnx2\n",
    "    else:\n",
    "        expected_coord = (prob.unsqueeze(-1)*sample_grids).sum(2)  # Bxnx2\n",
    "    if loc_rand:\n",
    "        expected_coord_org = expected_coord\n",
    "        expected_coord = expected_coord + 0.707*window_size*(2*torch.rand(expected_coord.shape).type_as(expected_coord)-1)\n",
    "    boarder_mask = (expected_coord[:,:,0]>=-1) & (expected_coord[:,:,0]<=1) & (expected_coord[:,:,1]>=-1) & (expected_coord[:,:,1]<=1)\n",
    "    valid = valid & boarder_mask\n",
    "\n",
    "    var = torch.sum(sample_grids**2 * prob.unsqueeze(-1), dim=2) - expected_coord**2  # Bxnx2\n",
    "    std = torch.sum(torch.sqrt(torch.clamp(var, min=1e-10)), -1) \n",
    "    if visualize:\n",
    "        return expected_coord, expected_coord_org, valid, std, prob\n",
    "    else:\n",
    "        return expected_coord, expected_coord_org, valid, std\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_endpoints(coords, Fmat, h, w):\n",
    "    '''\n",
    "    return endpoints1 endpoints2 bxnx2\n",
    "    return valid bxn\n",
    "    '''\n",
    "    batch_size, n_pts, _ = coords.shape\n",
    "    coord_h = homogenize(coords).transpose(1, 2)\n",
    "    epipolar_line = Fmat.bmm(coord_h)\n",
    "    a = epipolar_line[:,0,:] #Bxn\n",
    "    b = epipolar_line[:,1,:]\n",
    "    c = epipolar_line[:,2,:]\n",
    "    point_l = torch.stack([torch.zeros_like(a), -c/b], -1) #Bxnx2\n",
    "    point_r = torch.stack([(w-1)*torch.ones_like(a), -(a*(w-1)+c)/b], -1)\n",
    "    point_u = torch.stack([-(b*(h-1)+c)/a, (h-1)*torch.ones_like(a)], -1)\n",
    "    point_b = torch.stack([-c/a, torch.zeros_like(a)], -1)\n",
    "    points = torch.stack([point_l, point_r, point_u, point_b], -1).transpose(2,3) #Bxnx4x2\n",
    "    mask = (points[:,:,:,0]>=0) & (points[:,:,:,0]<=w-1) & (points[:,:,:,1]>=0) & (points[:,:,:,1]<=h-1) #Bxnx4\n",
    "    valid = mask.sum(-1) == 2 #Bxn\n",
    "    mask[~valid] = torch.tensor([True, True, False, False]).to(mask.device)\n",
    "    points = points[mask].reshape(batch_size, n_pts, 2, 2)\n",
    "    points1 = points[:,:,0,:]\n",
    "    points2 = points[:,:,1,:]\n",
    "    return normalize_coords(points1,h,w), normalize_coords(points2,h,w), valid\n",
    "\n",
    "def get_expected_correspondence_within_window(feat1, featmap2, coord2_n, window_size, with_std=False, with_sim=False):\n",
    "    '''\n",
    "    :param feat1: the feature vectors of query points [batch_size, n_pts, n_dim]\n",
    "    :param featmap2: the feature maps of the reference image [batch_size, n_dim, h, w]\n",
    "    :param coord2_n: normalized center locations [batch_size, n_pts, 2]\n",
    "    :param with_std: if True, return the standard deviation\n",
    "    :return: the normalized expected correspondence locations, [batch_size, n_pts, 2], optionally with std\n",
    "    '''\n",
    "    batch_size, n_dim, h2, w2 = featmap2.shape\n",
    "    n_pts = coord2_n.shape[1]\n",
    "    grid_n = gen_grid(h_min=-window_size, h_max=window_size,\n",
    "                      w_min=-window_size, w_max=window_size,\n",
    "                      len_h=int(window_size*h2), len_w=int(window_size*w2))\n",
    "\n",
    "    grid_n_ = grid_n.repeat(batch_size, 1, 1, 1).to(coord2_n)  # Bx1xhwx2\n",
    "    coord2_n_grid = coord2_n.unsqueeze(-2) + grid_n_  # Bxnxhwx2\n",
    "    feat2_win = F.grid_sample(featmap2, coord2_n_grid, padding_mode='zeros', align_corners=False).permute(0, 2, 3, 1)  # Bxnxhwxd\n",
    "\n",
    "    feat1 = feat1.unsqueeze(-2)\n",
    "\n",
    "    prob, sim = compute_prob(feat1.reshape(batch_size*n_pts, -1, n_dim),\n",
    "                        feat2_win.reshape(batch_size*n_pts, -1, n_dim), return_sim=True)#.reshape(batch_size, n_pts, -1)\n",
    "    prob = prob.reshape(batch_size, n_pts, -1)\n",
    "\n",
    "    expected_coord2_n = torch.sum(coord2_n_grid * prob.unsqueeze(-1), dim=2)  # Bxnx2\n",
    "\n",
    "    re_list = [expected_coord2_n, coord2_n_grid]\n",
    "    if with_std:\n",
    "        var = torch.sum(coord2_n_grid**2 * prob.unsqueeze(-1), dim=2) - expected_coord2_n**2  # Bxnx2\n",
    "        std = torch.sum(torch.sqrt(torch.clamp(var, min=1e-10)), -1)  # Bxn\n",
    "        # return expected_coord2_n, coord2_n_grid, std, prob\n",
    "        re_list.append(std)\n",
    "        re_list.append(prob)\n",
    "    # else:\n",
    "    #     return expected_coord2_n, coord2_n_grid\n",
    "    if with_sim:\n",
    "        re_list.append(sim.reshape(batch_size, n_pts, int(window_size*h2), int(window_size*w2)))\n",
    "    return tuple(re_list)\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_kpts_disk(inputs, outputs, grid_size, keep_spatial=False):\n",
    "    preds1 = outputs['preds1']\n",
    "    preds2 = outputs['preds2']\n",
    "\n",
    "    kp_map1, kp_map2 = preds1['local_point'], preds2['local_point']\n",
    "    kps1, logp1, accept_mask1 = generate_kpts_disk_single(kp_map1, grid_size)\n",
    "    kps2, logp2, accept_mask2 = generate_kpts_disk_single(kp_map2, grid_size)\n",
    "    return kps1, kps2, logp1, logp2\n",
    "\n",
    "def generate_kpts_disk_single(kp_map, grid_size):\n",
    "    b,_,h,w = kp_map.shape \n",
    "    grids_org = gen_grid(h_min=-1, h_max=1, w_min=-1, w_max=1, len_h=h, len_w=w)\n",
    "    grids_org = grids_org.reshape(h, w, 2)[None, :, :, :].repeat(b, 1, 1, 1).to(kp_map)\n",
    "    grids_org = grids_org.permute(0,3,1,2)\n",
    "\n",
    "    grids_unfold = unfold(grids_org, grid_size) # bx2x(h//g)x(w//g)x(g*g)\n",
    "    kpmap_unfold = unfold(kp_map, grid_size)\n",
    "\n",
    "    proposal_dist = Categorical(logits=kpmap_unfold)\n",
    "    proposals     = proposal_dist.sample() # bx1x(h//g)x(w//g)\n",
    "    proposal_logp = proposal_dist.log_prob(proposals)\n",
    "\n",
    "    accept_logits = torch.gather(logits, dim=-1, index=proposals[..., None]).squeeze(-1) # bx1x(h//g)x(w//g)\n",
    "\n",
    "    accept_dist    = Bernoulli(logits=accept_logits)\n",
    "    accept_samples = accept_dist.sample() # bx1x(h//g)x(w//g)\n",
    "    accept_logp    = accept_dist.log_prob(accept_samples) # for accepted points, equals to sigmoid() then log(); for denied, (1-sigmoid).log\n",
    "    accept_mask    = accept_samples == 1.\n",
    "\n",
    "    logp = proposal_logp + accept_logp\n",
    "    kps = grids_unfold.gather(dim=4, index=proposals.unsqueeze(-1).repeat(1,2,1,1,1))\n",
    "    return kps, logp, accept_mask\n",
    "\n",
    "def mnn_matcher(descriptors_a, descriptors_b):\n",
    "    device = descriptors_a.device\n",
    "    sim = descriptors_a @ descriptors_b.t()\n",
    "    nn12 = torch.max(sim, dim=1)[1]\n",
    "    nn21 = torch.max(sim, dim=0)[1]\n",
    "    ids1 = torch.arange(0, sim.shape[0], device=device)\n",
    "    mask = (ids1 == nn21[nn12])\n",
    "    matches = torch.stack([ids1[mask], nn12[mask]])\n",
    "    return matches.t().data.cpu().numpy()\n",
    "\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb5a89cb-5b05-4454-ae61-90587941c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(inputs, outputs):\n",
    "        desc_f = outputs['desc_map']\n",
    "        # desc_c = outputs['desc_map'][0]\n",
    "        name = inputs['name1'][0]\n",
    "\n",
    "        # b,c,h,w = inputs['im1'].shape\n",
    "        b,c,h,w = inputs['im1'].shape\n",
    "\n",
    "        # self.sift_kp:\n",
    "        coords = inputs['coord1']\n",
    "        coord_n = normalize_coords(coords, h, w)\n",
    "        print(coord_n.shape)\n",
    "        kp_score = torch.ones_like(coord_n)[:,:,:1]\n",
    "            \n",
    "        cur_name_split = name.split('/')\n",
    "        if cur_name_split[0] == 'query':\n",
    "            coord_n, kp_score = self.detector(outputs['local_point'], **self.config['detector_config_query'])\n",
    "        else:\n",
    "            coord_n, kp_score = self.detector(outputs['local_point'], **self.config['detector_config'])\n",
    "\n",
    "        coords = denormalize_coords(coord_n, h, w)\n",
    "\n",
    "        feat_f = sample_feat_by_coord(desc_f, coord_n, 'cos')\n",
    "        # feat_c = sample_feat_by_coord(desc_c, coord_n, self.config['loss_distance']=='cos')\n",
    "        # desc = torch.cat((feat_c, feat_f), -1)\n",
    "        kpt = coords.cpu().numpy().squeeze(0)\n",
    "\n",
    "        # scale for inloc\n",
    "        if 'scale' in list(inputs.keys()):\n",
    "            kpt = kpt*inputs['scale'].cpu().numpy()\n",
    "\n",
    "        return {\n",
    "            'kpt':  kpt,\n",
    "            'desc': feat_f,\n",
    "            'kp_score': kp_score\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af8b24ec-f689-480e-bed6-c2303f17676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extractor():\n",
    "    bar = tqdm(aachen_dataloader, total=int(len(aachen_dataloader)), ncols=80)\n",
    "    color = np.array(range(256)).astype(np.float64)[None,:].repeat(30, axis=0)\n",
    "    color = np.concatenate([np.zeros((30,20)),255*np.ones((30,20)),color], axis=1)\n",
    "    color = tensor2array(torch.tensor(color))[:3,:,:].transpose(1,2,0)\n",
    "    color = Im.fromarray((255*color).astype(np.uint8))\n",
    "    color.save('img_file/0_colorbar.jpg')\n",
    "    name_list = ''\n",
    "    \n",
    "    for idx, inputs in enumerate(bar):\n",
    "        # print(inputs.shape)\n",
    "        for key, val in inputs.items():\n",
    "            if key == 'name1' or key == 'pad1':\n",
    "                continue\n",
    "            inputs[key] = val.to(\"cuda\")\n",
    "        message = inputs['name1'][0]\n",
    "        # print(inputs['im1'].shape)\n",
    "        # print(inputs['im1'].dim())\n",
    "\n",
    "        # batch_size가 10인 경우\n",
    "        # batch_size = 10\n",
    "        # batch 차원 추가하여 4D로 변환\n",
    "        # batch_size = 1\n",
    "        # input_data_4d = torch.unsqueeze(inputs['im1'], dim=0).expand(batch_size, -1, -1, -1)\n",
    "        \n",
    "        \n",
    "        outputs = net1(inputs['im1'])\n",
    "        print(outputs['desc_map'].shape)\n",
    "        \n",
    "        # print(outputs['desc_map'])\n",
    "\n",
    "    #     processed = process(inputs, outputs)\n",
    "    #     message += save_desc(inputs, outputs, processed)\n",
    "    #     name_list += '{} {}\\n'.format(idx, inputs['name1'][0])\n",
    "        \n",
    "    #     torch.cuda.empty_cache()\n",
    "    # with open(self.img_root/'name_list.txt', 'w') as f:\n",
    "    #     f.write(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29bed85b-e44f-4afb-8804-bf5936cec15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                        | 1/7712 [00:00<1:12:10,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 264, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 2/7712 [00:00<53:19,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 180, 320])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 3/7712 [00:01<47:04,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 160, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 4/7712 [00:01<48:53,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 264, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 5/7712 [00:02<54:41,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 300, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 6/7712 [00:02<46:17,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 160, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 7/7712 [00:02<47:16,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 264, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 8/7712 [00:02<41:48,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 160, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 9/7712 [00:03<51:45,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 400, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 10/7712 [00:03<51:11,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 400, 264])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 11/7712 [00:04<53:41,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 400, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 12/7712 [00:04<52:40,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 400, 264])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 13/7712 [00:05<46:14,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 160, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 14/7712 [00:05<46:09,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 264, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 15/7712 [00:05<49:41,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 300, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 16/7712 [00:06<52:38,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 400, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 17/7712 [00:06<51:48,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 264, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 17/7712 [00:07<53:30,  2.40it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mextractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[59], line 11\u001b[0m, in \u001b[0;36mextractor\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m color\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_file/0_colorbar.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m name_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(bar):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# print(inputs.shape)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname1\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.pyenv/versions/vl-pipeline/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/mnt/hdd4T/minseong/github/VL-matching-localization-pipeline/my_pipeline/dataloader/aachen_loader.py:66\u001b[0m, in \u001b[0;36mAachen_Day_Night.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     64\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(im, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2GRAY)\n\u001b[1;32m     65\u001b[0m kpts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msift\u001b[38;5;241m.\u001b[39mdetect(gray)\n\u001b[0;32m---> 66\u001b[0m kpts \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkpts\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m coord \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(kpts)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     68\u001b[0m im1_ori \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(im)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a77bfff-968a-4348-8139-86ee89fe40e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd24b25-21ec-40b0-977c-6caac64d9cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7836f70-a470-4219-9cf6-49fbd9856501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b832b473-0c53-4b11-8d10-f6bd63bc5cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1f19a-594b-46e1-8f4d-a3ec49c06c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6444a355-e1b0-4b97-ba82-bb17e7c9f02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65768d3b-583d-43a1-95ae-5eccfeab349c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81f3ee-c885-4d65-99ac-207785b055aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5f51d-84aa-4b6f-8700-abccb220c556",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
