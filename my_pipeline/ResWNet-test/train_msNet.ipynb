{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"mps\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "width_out = 128\n",
    "height_out = 128"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "rt_path = \"datasets/\"\n",
    "TRAIN_PATH = os.path.join(rt_path, \"stage1_train/\")\n",
    "TEST_PATH = os.path.join(rt_path, \"stage1_test/\")\n",
    "\n",
    "train_dir = os.listdir(TRAIN_PATH)\n",
    "test_dir = os.listdir(TEST_PATH)\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n",
    "\n",
    "x_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "y_train = np.zeros((len(train_ids), height_out, width_out, 1), dtype=bool)\n",
    "x_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "for i, id_ in enumerate(train_ids):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = cv2.imread(path+'/images/'+id_+'.png')\n",
    "    img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    x_train[i] = img\n",
    "\n",
    "    mask = np.zeros((height_out, width_out, 1), dtype=bool)\n",
    "    mask_path = path+'/masks/'\n",
    "    for id_ in os.listdir(mask_path):\n",
    "        mask_ = cv2.imread(mask_path+id_, 0)\n",
    "        mask_ = cv2.resize(mask_, (height_out, width_out))\n",
    "        mask_ = np.expand_dims(mask_, axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    y_train[i] = mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "np.save(\"datasets/x_train.npy\", x_train)\n",
    "np.save(\"datasets/y_train.npy\", y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images_np, masks_np):\n",
    "        self.images_np = images_np\n",
    "        self.masks_np = masks_np\n",
    "\n",
    "    def transform(self, image_np, mask_np):\n",
    "        ToPILImage = transforms.ToPILImage()\n",
    "        image = ToPILImage(image_np)\n",
    "        mask = ToPILImage(mask_np.astype(np.int32))\n",
    "\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_np)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_np = self.images_np[idx]\n",
    "        mask_np = self.masks_np[idx]\n",
    "        image, mask = self.transform(image_np, mask_np)\n",
    "\n",
    "        return image, mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=0)\n",
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_dataset = CustomDataset(x_val, y_val)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kweonminseong/.pyenv/versions/ResWNet/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/kweonminseong/.pyenv/versions/ResWNet/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/Users/kweonminseong/.pyenv/versions/ResWNet/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from nets.minseongNet.ResWNet import ResWNet\n",
    "from nets.minseongNet.ResUNet_F2R import ResUNet_F2R, Dacon_ResUNet\n",
    "\n",
    "# model = Dacon_ResUNet(num_classes=1).to(device)\n",
    "model = ResWNet().to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "epochs=25 # 3 -> 25\n",
    "alpha=5\n",
    "batch_size = 16 # 각자 메모리 상태에 맞게 변경하셔도 됩니다.\n",
    "# nn.CrossEntropyLoss() (paper) -> BCELoss()\n",
    "criterion=nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "train_iou_sum = 0\n",
    "valid_iou_sum = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def iou(pred, target, n_classes = 2):\n",
    "\n",
    "    iou = []\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "\n",
    "    # Ignore IoU for background class (\"0\")\n",
    "    for cls in range(1, n_classes):\n",
    "        pred_inds = pred == cls\n",
    "        target_inds = target == cls\n",
    "        intersection = (pred_inds[target_inds]).long().sum().data.cpu().item()\n",
    "        union = pred_inds.long().sum().data.cpu().item() + target_inds.long().sum().data.cpu().item() - intersection\n",
    "\n",
    "        if union == 0:\n",
    "            iou.append(float('nan'))  # If there is no ground truth, do not include in evaluation\n",
    "        else:\n",
    "            iou.append(float(intersection) / float(max(union, 1)))\n",
    "\n",
    "    return sum(iou)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def iou_metric(y_pred, y_true, n_classes = 2):\n",
    "    miou = []\n",
    "    for i in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = (y_pred > i)\n",
    "        iou_init = iou(y_pred_, y_true, n_classes = n_classes)\n",
    "        miou.append(iou_init)\n",
    "\n",
    "    return sum(miou)/len(miou)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f7eca578f4a47f0931ac2245e019221"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kweonminseong/.pyenv/versions/ResWNet/lib/python3.9/site-packages/torch/nn/functional.py:3737: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/tc97y9y91mqdvfbhjdvdfcsm0000gn/T/ipykernel_6467/487936267.py:11: UserWarning: MPS: no support for int64 reduction ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:144.)\n",
      "  intersection = (pred_inds[target_inds]).long().sum().data.cpu().item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  1  Training Loss:  tensor(0.3393, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.1979, device='mps:0')\n",
      "Training IoU:  0.15108692301894566 Validation IoU:  0.3856050380655017\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4a005b6bbd443eaa385206f0fa45e11"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  2  Training Loss:  tensor(0.1888, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.1655, device='mps:0')\n",
      "Training IoU:  0.4281227467789176 Validation IoU:  0.36521152724490624\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47667a940f6e41d283c1a127346e7585"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  3  Training Loss:  tensor(0.1532, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.1267, device='mps:0')\n",
      "Training IoU:  0.5308374896982363 Validation IoU:  0.5462949863105327\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcdda2b5bbb04798b17f5b82873f8663"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  4  Training Loss:  tensor(0.1330, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.1176, device='mps:0')\n",
      "Training IoU:  0.5782222336492884 Validation IoU:  0.6014696433534304\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94e9da1ddf404f1a9e123fa31382e75e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  5  Training Loss:  tensor(0.1231, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.1205, device='mps:0')\n",
      "Training IoU:  0.6030344672601572 Validation IoU:  0.6870626801355003\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "900992e56b644a718a6e8b310309c9b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  6  Training Loss:  tensor(0.1239, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.1105, device='mps:0')\n",
      "Training IoU:  0.5962518662411824 Validation IoU:  0.6556650030451378\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b80c85ba95a9490399b5360d69eea3bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  7  Training Loss:  tensor(0.1200, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.1117, device='mps:0')\n",
      "Training IoU:  0.6087466439598078 Validation IoU:  0.5772850618220341\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5f12729bd504971be46d6bd825de811"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  8  Training Loss:  tensor(0.1159, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.1170, device='mps:0')\n",
      "Training IoU:  0.6140123166754548 Validation IoU:  0.6966632644515695\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e2e63391cd74a6a8a50c30756a99e76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  9  Training Loss:  tensor(0.1062, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.1064, device='mps:0')\n",
      "Training IoU:  0.6415524131441768 Validation IoU:  0.5913233100210655\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9b24993695c4380ae612e5f654b1cad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  10  Training Loss:  tensor(0.1038, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0971, device='mps:0')\n",
      "Training IoU:  0.6536626627887933 Validation IoU:  0.6478293072918957\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c5d164b36984332b4cce18f514808d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  11  Training Loss:  tensor(0.1051, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.1018, device='mps:0')\n",
      "Training IoU:  0.6415493126698235 Validation IoU:  0.655997224054096\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1cb977232b44d5d8fb2f92fc24c20e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  12  Training Loss:  tensor(0.0975, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.1219, device='mps:0')\n",
      "Training IoU:  0.6672718749619075 Validation IoU:  0.730732633991514\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5bbaf04a73ad4d6e8d0e916ebf32f5b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  13  Training Loss:  tensor(0.0926, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0948, device='mps:0')\n",
      "Training IoU:  0.6866001863813878 Validation IoU:  0.6626603191405823\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acc893dce7b54e64955d207695b7f2b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  14  Training Loss:  tensor(0.0945, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0918, device='mps:0')\n",
      "Training IoU:  0.6803575031837108 Validation IoU:  0.674405876067714\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34eebfa6567f410dbdfb6dd1dc2397bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  15  Training Loss:  tensor(0.0863, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0931, device='mps:0')\n",
      "Training IoU:  0.7009748453985957 Validation IoU:  0.6933792200668145\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07460b2353f94ee4a1f7c823176830f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  16  Training Loss:  tensor(0.0868, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0895, device='mps:0')\n",
      "Training IoU:  0.7017412689989072 Validation IoU:  0.7108620710380527\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21899297fa994523b361885ae5279021"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  17  Training Loss:  tensor(0.0870, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0924, device='mps:0')\n",
      "Training IoU:  0.7011455033696666 Validation IoU:  0.6890195391488417\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cdd3b3305db4357a8d2b6159470a916"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  18  Training Loss:  tensor(0.0843, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0940, device='mps:0')\n",
      "Training IoU:  0.7059290882456589 Validation IoU:  0.7152744093692134\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd4c20dc09494b2a857676fe02b8e77a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  19  Training Loss:  tensor(0.0910, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0893, device='mps:0')\n",
      "Training IoU:  0.6943520136161543 Validation IoU:  0.7183754807094532\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94df4575a65542d9a5ee27738f67e9d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  20  Training Loss:  tensor(0.0844, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0873, device='mps:0')\n",
      "Training IoU:  0.7078374325178928 Validation IoU:  0.6896976470144197\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e6b52e85d79425c9ceb6fcb177bcf79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  21  Training Loss:  tensor(0.0764, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0786, device='mps:0')\n",
      "Training IoU:  0.7359212188860305 Validation IoU:  0.7505509706459527\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "786fd4b75fec4e9780620a006bda83be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  22  Training Loss:  tensor(0.0740, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0816, device='mps:0')\n",
      "Training IoU:  0.7475116820709512 Validation IoU:  0.7323792853054124\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1858e2a7fc49445189c14274bb0fc6a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  23  Training Loss:  tensor(0.0738, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0838, device='mps:0')\n",
      "Training IoU:  0.7398393151662477 Validation IoU:  0.6889606275600523\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f84879b8eee44088cb54b88e82151fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  24  Training Loss:  tensor(0.0682, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0822, device='mps:0')\n",
      "Training IoU:  0.7572205871938137 Validation IoU:  0.698473278246931\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/32 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abdce22675f34fdd9f14b8c3d54e28a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([16, 1, 128, 128])\n",
      "torch.Size([6, 1, 128, 128])\n",
      "Epoch  25  Training Loss:  tensor(0.0680, device='mps:0', grad_fn=<DivBackward0>) Validation Loss:  tensor(0.0775, device='mps:0')\n",
      "Training IoU:  0.762562349019132 Validation IoU:  0.7548256561869187\n",
      "Training Mean IoU: 0.64  Validation Mean IoU: 0.65\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "train_iou_list = []\n",
    "val_iou_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_iou = 0\n",
    "\n",
    "    for image, mask in tqdm(train_loader):\n",
    "        image = image.to(device)\n",
    "        mask = mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image.float())\n",
    "        print(outputs.shape)\n",
    "        loss = criterion(outputs.float(), mask.float())\n",
    "        train_loss += loss\n",
    "\n",
    "        train_iou += iou_metric(outputs, mask)\n",
    "        rev_iou = 16 - iou_metric(outputs, mask)\n",
    "        loss += alpha * rev_iou\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0\n",
    "        valid_iou = 0\n",
    "\n",
    "        for image_val, mask_val in valid_loader:\n",
    "            image_val = image_val.to(device)\n",
    "            mask_val = mask_val.to(device)\n",
    "            output_val = model(image_val.float())\n",
    "            valid_loss += criterion(output_val.float(), mask_val.float())\n",
    "            valid_iou += iou_metric(output_val, mask_val)\n",
    "\n",
    "    print(\"Epoch \", epoch + 1, \" Training Loss: \", train_loss/len(train_loader), \"Validation Loss: \", valid_loss/len(valid_loader))\n",
    "    print(\"Training IoU: \", train_iou/len(train_loader), \"Validation IoU: \", valid_iou/len(valid_loader))\n",
    "    train_iou_sum += train_iou/len(train_loader)\n",
    "    valid_iou_sum += valid_iou/len(valid_loader)\n",
    "\n",
    "    # visualization\n",
    "    train_loss_list.append(train_loss/len(train_loader))\n",
    "    val_loss_list.append(valid_loss/len(valid_loader))\n",
    "    train_iou_list.append(train_iou/len(train_loader))\n",
    "    val_iou_list.append(valid_iou/len(valid_loader)\n",
    "                        )\n",
    "\n",
    "print(\"Training Mean IoU: {:.2f}\".format(train_iou_sum/epochs), \" Validation Mean IoU: {:.2f}\".format(valid_iou_sum/epochs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
